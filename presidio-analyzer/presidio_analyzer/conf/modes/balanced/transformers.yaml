# Balanced mode: Good accuracy with moderate latency
# Use case: General purpose, recommended starting point
# Expected latency: ~50-100ms per text
#
# This mode uses a Transformer NER model (Stanford De-identifier) for improved
# accuracy while maintaining reasonable latency.
# Trade-off: Slower than fast mode, but significantly more accurate.

nlp_engine_name: transformers
models:
  -
    lang_code: en
    model_name:
      spacy: en_core_web_sm
      transformers: StanfordAIMI/stanford-deidentifier-base

ner_model_configuration:
  labels_to_ignore:
  - O
  aggregation_strategy: max  # "simple", "first", "average", "max"
  stride: 16                 # Overlap for long text processing
  alignment_mode: expand     # "strict", "contract", "expand"
  model_to_presidio_entity_mapping:
    PER: PERSON
    PERSON: PERSON
    LOC: LOCATION
    LOCATION: LOCATION
    GPE: LOCATION
    ORG: ORGANIZATION
    ORGANIZATION: ORGANIZATION
    NORP: NRP
    AGE: AGE
    ID: ID
    EMAIL: EMAIL
    PATIENT: PERSON
    STAFF: PERSON
    HOSP: ORGANIZATION
    PATORG: ORGANIZATION
    DATE: DATE_TIME
    TIME: DATE_TIME
    PHONE: PHONE_NUMBER
    HCW: PERSON
    HOSPITAL: LOCATION
    FACILITY: LOCATION
    VENDOR: ORGANIZATION

  low_confidence_score_multiplier: 0.4
  low_score_entity_names:
  - ID
