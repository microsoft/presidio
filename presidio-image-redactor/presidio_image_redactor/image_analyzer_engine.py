from typing import List, Tuple, Optional, Dict, Union
from copy import deepcopy
import numpy as np
from presidio_analyzer import AnalyzerEngine, RecognizerResult

from presidio_image_redactor import OCR, TesseractOCR, ImagePreprocessor
from presidio_image_redactor.entities import ImageRecognizerResult

from PIL import Image, ImageChops
import matplotlib.pyplot as plt
import matplotlib
import io


class ImageAnalyzerEngine:
    """ImageAnalyzerEngine class.

    :param analyzer_engine: The Presidio AnalyzerEngine instance
        to be used to detect PII in text
    :param ocr: the OCR object to be used to detect text in images.
    :param image_preprocessor: The ImagePreprocessor object to be
        used to preprocess the image
    """

    def __init__(
        self,
        analyzer_engine: Optional[AnalyzerEngine] = None,
        ocr: Optional[OCR] = None,
        image_preprocessor: Optional[ImagePreprocessor] = None,
    ):
        if not analyzer_engine:
            analyzer_engine = AnalyzerEngine()
        self.analyzer_engine = analyzer_engine

        if not ocr:
            ocr = TesseractOCR()
        self.ocr = ocr

        if not image_preprocessor:
            image_preprocessor = ImagePreprocessor()
        self.image_preprocessor = image_preprocessor

    def analyze(
        self, image: object, ocr_kwargs: Optional[dict] = None, **text_analyzer_kwargs
    ) -> List[ImageRecognizerResult]:
        """Analyse method to analyse the given image.

        :param image: PIL Image/numpy array or file path(str) to be processed.
        :param ocr_kwargs: Additional params for OCR methods.
        :param text_analyzer_kwargs: Additional values for the analyze method
        in AnalyzerEngine.

        :return: List of the extract entities with image bounding boxes.
        """
        # Perform OCR
        perform_ocr_kwargs, ocr_threshold = self._parse_ocr_kwargs(ocr_kwargs)
        image, preprocessing_metadata = self.image_preprocessor.preprocess_image(image)
        ocr_result = self.ocr.perform_ocr(image, **perform_ocr_kwargs)
        ocr_result = self.remove_space_boxes(ocr_result)

        if preprocessing_metadata and ("scale_factor" in preprocessing_metadata):
            ocr_result = self._scale_bbox_results(
                ocr_result, preprocessing_metadata["scale_factor"]
            )

        # Apply OCR confidence threshold if it is passed in
        if ocr_threshold:
            ocr_result = self.threshold_ocr_result(ocr_result, ocr_threshold)

        # Analyze text
        text = self.ocr.get_text_from_ocr_dict(ocr_result)

        analyzer_result = self.analyzer_engine.analyze(
            text=text, language="en", **text_analyzer_kwargs
        )
        allow_list = self._check_for_allow_list(text_analyzer_kwargs)
        bboxes = self.map_analyzer_results_to_bounding_boxes(
            analyzer_result, ocr_result, text, allow_list
        )

        return bboxes

    @staticmethod
    def threshold_ocr_result(ocr_result: dict, ocr_threshold: float) -> dict:
        """Filter out OCR results below confidence threshold.

        :param ocr_result: OCR results (raw).
        :param ocr_threshold: Threshold value between -1 and 100.

        :return: OCR results with low confidence items removed.
        """
        if ocr_threshold < -1 or ocr_threshold > 100:
            raise ValueError("ocr_threshold must be between -1 and 100")

        # Get indices of items above threshold
        idx = list()
        for i, val in enumerate(ocr_result["conf"]):
            if float(val) >= ocr_threshold:
                idx.append(i)

        # Only retain high confidence items
        filtered_ocr_result = {}
        for key in list(ocr_result.keys()):
            filtered_ocr_result[key] = [ocr_result[key][i] for i in idx]

        return filtered_ocr_result

    @staticmethod
    def remove_space_boxes(ocr_result: dict) -> dict:
        """Remove OCR bboxes that are for spaces.

        :param ocr_result: OCR results (raw or thresholded).
        :return: OCR results with empty words removed.
        """
        # Get indices of items with no text
        idx = list()
        for i, text in enumerate(ocr_result["text"]):
            is_not_space = text.isspace() is False
            if text != "" and is_not_space:
                idx.append(i)

        # Only retain items with text
        filtered_ocr_result = {}
        for key in list(ocr_result.keys()):
            filtered_ocr_result[key] = [ocr_result[key][i] for i in idx]

        return filtered_ocr_result

    @staticmethod
    def map_analyzer_results_to_bounding_boxes(
        text_analyzer_results: List[RecognizerResult],
        ocr_result: dict,
        text: str,
        allow_list: List[str],
    ) -> List[ImageRecognizerResult]:
        """Map extracted PII entities to image bounding boxes.

        Matching is based on the position of the recognized entity from analyzer
        and word (in ocr dict) in the text.

        :param text_analyzer_results: PII entities recognized by presidio analyzer
        :param ocr_result: dict results with words and bboxes from OCR
        :param text: text the results are based on
        :param allow_list: List of words to not redact

        return: list of extracted entities with image bounding boxes
        """
        if (not ocr_result) or (not text_analyzer_results):
            return []

        bboxes = []
        proc_indexes = 0
        indexes = len(text_analyzer_results)

        pos = 0
        iter_ocr = enumerate(ocr_result["text"])
        for index, word in iter_ocr:
            if not word:
                pos += 1
            else:
                for element in text_analyzer_results:
                    text_element = text[element.start : element.end]
                    # check position and text of ocr word matches recognized entity
                    if (
                        max(pos, element.start) < min(element.end, pos + len(word))
                    ) and ((text_element in word) or (word in text_element)):
                        yes_make_bbox_for_word = (
                            (word is not None)
                            and (word != "")
                            and (word.isspace() is False)
                            and (word not in allow_list)
                        )
                        # Do not add bbox for standalone spaces / empty strings
                        if yes_make_bbox_for_word:
                            bboxes.append(
                                ImageRecognizerResult(
                                    element.entity_type,
                                    element.start,
                                    element.end,
                                    element.score,
                                    ocr_result["left"][index],
                                    ocr_result["top"][index],
                                    ocr_result["width"][index],
                                    ocr_result["height"][index],
                                )
                            )

                            # add bounding boxes for all words in ocr dict
                            # contained within the text of recognized entity
                            # based on relative position in the full text
                            while pos + len(word) < element.end:
                                prev_word = word
                                index, word = next(iter_ocr)
                                yes_make_bbox_for_word = (
                                    (word is not None)
                                    and (word != "")
                                    and (word.isspace() is False)
                                    and (word not in allow_list)
                                )
                                if yes_make_bbox_for_word:
                                    bboxes.append(
                                        ImageRecognizerResult(
                                            element.entity_type,
                                            element.start,
                                            element.end,
                                            element.score,
                                            ocr_result["left"][index],
                                            ocr_result["top"][index],
                                            ocr_result["width"][index],
                                            ocr_result["height"][index],
                                        )
                                    )
                                pos += len(prev_word) + 1
                            proc_indexes += 1

                if proc_indexes == indexes:
                    break
                pos += len(word) + 1

        return bboxes

    @staticmethod
    def _scale_bbox_results(
        ocr_result: Dict[str, List[Union[int, str]]], scale_factor: float
    ) -> Dict[str, float]:
        """Scale down the bounding box results based on a scale percentage.

        :param ocr_result: OCR results (raw).
        :param scale_percent: Scale percentage for resizing the bounding box.

        :return: OCR results (scaled).
        """
        scaled_results = deepcopy(ocr_result)
        coordinate_keys = ["left", "top"]
        dimension_keys = ["width", "height"]

        for coord_key in coordinate_keys:
            scaled_results[coord_key] = [
                int(np.ceil((x) / (scale_factor))) for x in scaled_results[coord_key]
            ]

        for dim_key in dimension_keys:
            scaled_results[dim_key] = [
                max(1, int(np.ceil(x / (scale_factor))))
                for x in scaled_results[dim_key]
            ]
        return scaled_results

    @staticmethod
    def _remove_bbox_padding(
        analyzer_bboxes: List[Dict[str, Union[str, float, int]]],
        padding_width: int,
    ) -> List[Dict[str, int]]:
        """Remove added padding in bounding box coordinates.

        :param analyzer_bboxes: The bounding boxes from analyzer results.
        :param padding_width: Pixel width used for padding (0 if no padding).

        :return: Bounding box information per word.
        """

        unpadded_results = deepcopy(analyzer_bboxes)
        if padding_width < 0:
            raise ValueError("Padding width must be a non-negative integer.")

        coordinate_keys = ["left", "top"]
        for coord_key in coordinate_keys:
            unpadded_results[coord_key] = [
                max(0, x - padding_width) for x in unpadded_results[coord_key]
            ]

        return unpadded_results

    @staticmethod
    def _parse_ocr_kwargs(ocr_kwargs: dict) -> Tuple[dict, float]:
        """Parse the OCR-related kwargs.

        :param ocr_kwargs: Parameters for OCR operations.

        :return: Params for ocr.perform_ocr and ocr_threshold
        """
        ocr_threshold = None
        if ocr_kwargs is not None:
            if "ocr_threshold" in ocr_kwargs:
                ocr_threshold = ocr_kwargs["ocr_threshold"]
                ocr_kwargs = {
                    key: value
                    for key, value in ocr_kwargs.items()
                    if key != "ocr_threshold"
                }
        else:
            ocr_kwargs = {}

        return ocr_kwargs, ocr_threshold

    @staticmethod
    def _check_for_allow_list(text_analyzer_kwargs: dict) -> List[str]:
        """Check the text_analyzer_kwargs for an allow_list.

        :param text_analyzer_kwargs: Text analyzer kwargs.
        :return: The allow list if it exists.
        """
        allow_list = []
        if text_analyzer_kwargs is not None:
            if "allow_list" in text_analyzer_kwargs:
                allow_list = text_analyzer_kwargs["allow_list"]

        return allow_list

    @staticmethod
    def fig2img(fig: matplotlib.figure.Figure) -> Image:
        """Convert a Matplotlib figure to a PIL Image and return it.

        :param fig: Matplotlib figure.

        :return: Image of figure.
        """
        buf = io.BytesIO()
        fig.savefig(buf)
        buf.seek(0)
        img = Image.open(buf)

        return img

    @staticmethod
    def get_pii_bboxes(
        ocr_bboxes: List[dict],
        analyzer_bboxes: List[dict]
    ) -> List[dict]:
        """Get a list of bboxes with is_PII property.

        :param ocr_bboxes: Bboxes from OCR results.
        :param analyzer_bboxes: Bboxes from analyzer results.

        :return: All bboxes with appropriate label for whether it is PHI or not.
        """
        bboxes = []
        for ocr_bbox in ocr_bboxes:
            has_match = False

            # Check if we have the same bbox in analyzer results
            for analyzer_bbox in analyzer_bboxes:
                has_same_position = (ocr_bbox["left"] == analyzer_bbox["left"] and ocr_bbox["top"] == analyzer_bbox["top"])  # noqa: E501
                has_same_dimension = (ocr_bbox["width"] == analyzer_bbox["width"] and ocr_bbox["height"] == analyzer_bbox["height"])  # noqa: E501
                is_same = (has_same_position is True and has_same_dimension is True)

                if is_same is True:
                    current_bbox = analyzer_bbox
                    current_bbox["is_PII"] = True
                    has_match = True
                    break

            if has_match is False:
                current_bbox = ocr_bbox
                current_bbox["is_PII"] = False

            bboxes.append(current_bbox)

        return bboxes

    @classmethod
    def add_custom_bboxes(
        cls,
        image: Image,
        bboxes: List[dict],
        show_text_annotation: bool = True,
        use_greyscale_cmap: bool = False
    ) -> Image:
        """Add custom bounding boxes to image.

        :param image: Standard image of DICOM pixels.
        :param bboxes: List of bounding boxes to display (with is_PII field).
        :param gt_bboxes: Ground truth bboxes (list of dictionaries).
        :param show_text_annotation: True if you want text annotation for
        PHI status to display.
        :param use_greyscale_cmap: Use greyscale color map.
        :return: Image with bounding boxes drawn on.
        """
        image_custom = ImageChops.duplicate(image)
        image_x, image_y = image_custom.size

        fig, ax = plt.subplots()
        image_r = 70
        fig.set_size_inches(image_x / image_r, image_y / image_r)

        if len(bboxes) == 0:
            ax.imshow(image_custom)
            return image_custom
        else:
            for box in bboxes:
                try:
                    entity_type = box["entity_type"]
                except KeyError:
                    entity_type = "UNKNOWN"

                try:
                    if box["is_PII"]:
                        bbox_color = "r"
                    else:
                        bbox_color = "b"
                except KeyError:
                    bbox_color = "b"

                # Get coordinates and dimensions
                x0 = box["left"]
                y0 = box["top"]
                x1 = x0 + box["width"]
                y1 = y0 + box["height"]
                rect = matplotlib.patches.Rectangle(
                    (x0, y0),
                    x1 - x0, y1 - y0,
                    edgecolor=bbox_color,
                    facecolor="none"
                )
                ax.add_patch(rect)
                if show_text_annotation:
                    ax.annotate(
                        entity_type,
                        xy=(x0 - 3, y0 - 3),
                        xycoords="data",
                        bbox=dict(boxstyle="round4,pad=.5", fc="0.9"),
                    )
            if use_greyscale_cmap:
                ax.imshow(image_custom, cmap="gray")
            else:
                ax.imshow(image_custom)
            im_from_fig = cls.fig2img(fig)
            im_resized = im_from_fig.resize((image_x, image_y))

        return im_resized
